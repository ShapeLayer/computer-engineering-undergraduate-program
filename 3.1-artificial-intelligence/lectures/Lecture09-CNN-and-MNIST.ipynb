{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f37d13e",
   "metadata": {},
   "source": [
    "# 컨볼루션 네트워크를 이용해 MNIST 필기체 숫자 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9166141-e814-4858-b6d1-18f7b00a500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd13822-c3a7-42bd-8a68-b30561bbaac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e6b34-c5d2-4468-ac05-e490ad3cc28d",
   "metadata": {},
   "source": [
    "train: $60\\,000$ 장  \n",
    "test: $10\\,000$ 장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a80639-4d4e-4250-84d1-e4b993055f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60_000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10_000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea77fe-276b-4e3e-a843-97a93d157d0a",
   "metadata": {},
   "source": [
    "Why reshape $60\\,000 \\times 28 \\times 28 \\Rightarrow 60\\,000 \\times 28 \\times 28 \\times 1$ ?\n",
    "\n",
    "* Added 1 is about color channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c257ed-88a1-451b-963c-87bf9d4b59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceeec82-fc94-49e3-a0fe-d55a5609bb8f",
   "metadata": {},
   "source": [
    "Make each pixel value range $[0, 255]$ to $[0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08eacc-dd20-4152-bbbe-99d400066327",
   "metadata": {},
   "source": [
    "## Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383c1430-f81e-4ab7-97c0-e995b49b7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e974e-17ab-4ef9-b207-cdaa67c0fe62",
   "metadata": {},
   "source": [
    "### CNN Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e711d-0e58-40d2-a17e-58d69aa11f88",
   "metadata": {},
   "source": [
    "$(28 \\times 28) \\times 32 \\Rightarrow (26 \\times 26) \\times 32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa21cea-2636-4cd6-b27b-c54e0bf4c1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai-lecture/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-05-27 14:42:00.596788: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-05-27 14:42:00.596872: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-05-27 14:42:00.596919: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-05-27 14:42:00.597125: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-27 14:42:00.597175: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c84dac-2286-4c1e-823a-d188ccce21bb",
   "metadata": {},
   "source": [
    "$(26 \\times 26) \\times 32 \\Rightarrow (13 \\times 13) \\times 32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb15a5a-11e6-4587-864f-1ae4f3591f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffddde2-ed5c-4028-9e0a-8b8e59fad3fa",
   "metadata": {},
   "source": [
    "* Use $(32 \\times 32) \\times 64$\n",
    "    * 32 to 64\n",
    "\n",
    "$(13 \\times 13) \\times 32 \\Rightarrow (11 \\times 11) \\times 64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ad32d9-98c3-40ef-b68d-20e75f62f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8868ff7-0743-4d1a-8c91-d2a2c4284ecc",
   "metadata": {},
   "source": [
    "$(11 \\times 11) \\times 32 \\Rightarrow (5 \\times 5) \\times 64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187fa945-6017-41b0-9ea0-8817f733c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611742a-43b8-4284-906b-7782807a2061",
   "metadata": {},
   "source": [
    "$(5 \\times 5) \\times 64 \\Rightarrow (3 \\times 3) \\times 64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25b1d5a-556b-4a74-a383-bc0d32f883fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc1acb-0332-492b-b603-83cac06bed80",
   "metadata": {},
   "source": [
    "**Result**\n",
    "* $\\#W = 3 \\times 3 \\times 64$\n",
    "* $\\#b = 64$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb747b83-e7e4-4afe-a7f9-81d350ef5217",
   "metadata": {},
   "source": [
    "### Serialization and Fully Connected Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47aa389-5fa8-4007-bd07-476c3f9bf524",
   "metadata": {},
   "source": [
    "$3 \\times 3 \\times 64 \\Rightarrow 576$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c1e387-1f68-41bc-a478-07c102d6da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366eca6e-111b-49fe-babc-3a5ba8f05df5",
   "metadata": {},
   "source": [
    "**Fully Connected**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f29a3-116c-453f-bf33-3124c893faf7",
   "metadata": {},
   "source": [
    "$576 \\Rightarrow 64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21dd00ba-1b47-497c-af5d-89d113f114e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(64, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a650cd0-5500-4bf3-88bf-f6ad0926b224",
   "metadata": {},
   "source": [
    "$64 \\Rightarrow 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "504e7c49-465e-43b4-b530-22357634bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e29867-0399-4fbb-887e-7ffcf8d18af9",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3854628-5c21-4b79-92e4-2ff72b28edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81704507-7d87-487b-b4e2-c3fd7454147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 14:42:01.244030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8903 - loss: 0.3506\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3969s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.0517\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3289s\u001b[0m 2s/step - accuracy: 0.9893 - loss: 0.0341\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3659s\u001b[0m 2s/step - accuracy: 0.9914 - loss: 0.0263\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1005s\u001b[0m 536ms/step - accuracy: 0.9931 - loss: 0.0201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17fee1910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
